{"version":3,"file":"logger-worker.js","sourceRoot":"","sources":["../../src/workers/logger-worker.ts"],"names":[],"mappings":"AAAA,iCAAiC;;;;;;;;;;AAEjC,MAAM,OAAO,GAAG,OAAO,CAAC,GAAG,CAAC,sBAAsB,IAAI,yBAAyB,CAAC;AAShF;;;;GAIG;AAEH,MAAM,QAAQ,GAAc,EAAE,CAAC;AAC/B,MAAM,cAAc,GAAG,EAAE,CAAC;AAC1B,MAAM,cAAc,GAAG,IAAI,CAAC,CAAC,YAAY;AAEzC,MAAM,SAAS,GAAG,GAAwB,EAAE;IAC3C,IAAI,QAAQ,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;QAC3B,OAAO;IACR,CAAC;IAED,MAAM,UAAU,GAAG,QAAQ,CAAC,MAAM,CAAC,CAAC,EAAE,cAAc,CAAC,CAAC;IACtD,IAAI,CAAC;QACJ,MAAM,QAAQ,GAAG,MAAM,KAAK,CAAC,OAAO,EAAE;YACrC,MAAM,EAAE,MAAM;YACd,OAAO,EAAE;gBACR,cAAc,EAAE,kBAAkB;gBAClC,MAAM,EAAE,kBAAkB;aAC1B;YACD,IAAI,EAAE,IAAI,CAAC,SAAS,CAAC,UAAU,CAAC;SAChC,CAAC,CAAC;QAEH,IAAI,CAAC,QAAQ,CAAC,EAAE,EAAE,CAAC;YAClB,MAAM,IAAI,KAAK,CAAC,uBAAuB,QAAQ,CAAC,MAAM,EAAE,CAAC,CAAC;QAC3D,CAAC;QAED,OAAO,CAAC,GAAG,CAAC,mCAAmC,QAAQ,CAAC,MAAM,EAAE,CAAC,CAAC;IACnE,CAAC;IAAC,OAAO,KAAK,EAAE,CAAC;QAChB,OAAO,CAAC,KAAK,CACZ,qBAAqB,EACrB,KAAK,YAAY,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,MAAM,CAAC,KAAK,CAAC,CACtD,CAAC;QACF,+CAA+C;QAC/C,QAAQ,CAAC,OAAO,CAAC,GAAG,UAAU,CAAC,CAAC;IACjC,CAAC;AACF,CAAC,CAAA,CAAC;AAEF,wBAAwB;AACxB,WAAW,CAAC,SAAS,EAAE,cAAc,CAAC,CAAC;AAEvC,IAAI,CAAC,gBAAgB,CACpB,SAAS,EACT,CAAC,KAAyC,EAAE,EAAE;IAC7C,MAAM,EAAE,OAAO,EAAE,GAAG,KAAK,CAAC,IAAI,CAAC;IAC/B,QAAQ,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;IAEvB,gDAAgD;IAChD,IAAI,QAAQ,CAAC,MAAM,IAAI,cAAc,EAAE,CAAC;QACvC,KAAK,SAAS,EAAE,CAAC;IAClB,CAAC;AACF,CAAC,CACD,CAAC","sourcesContent":["/// <reference lib=\"webworker\" />\n\nconst API_URL = process.env.NEXT_PUBLIC_LOGGER_URL || \"https://log.bones.sh/v1\";\n\ninterface LogData {\n\tlevel: \"info\" | \"warn\" | \"error\";\n\tmessage: string;\n\ttimestamp: number;\n\tmetadata?: Record<string, unknown>;\n}\n\n/**\n * Logger Worker\n * This worker handles logging operations in batches to reduce API calls.\n * It will automatically flush logs every 5 seconds or when reaching batch size.\n */\n\nconst logQueue: LogData[] = [];\nconst MAX_BATCH_SIZE = 10;\nconst FLUSH_INTERVAL = 5000; // 5 seconds\n\nconst flushLogs = async (): Promise<void> => {\n\tif (logQueue.length === 0) {\n\t\treturn;\n\t}\n\n\tconst logsToSend = logQueue.splice(0, MAX_BATCH_SIZE);\n\ttry {\n\t\tconst response = await fetch(API_URL, {\n\t\t\tmethod: \"POST\",\n\t\t\theaders: {\n\t\t\t\t\"Content-Type\": \"application/json\",\n\t\t\t\tAccept: \"application/json\",\n\t\t\t},\n\t\t\tbody: JSON.stringify(logsToSend),\n\t\t});\n\n\t\tif (!response.ok) {\n\t\t\tthrow new Error(`HTTP error! status: ${response.status}`);\n\t\t}\n\n\t\tconsole.log(`Logs sent successfully. Status: ${response.status}`);\n\t} catch (error) {\n\t\tconsole.error(\n\t\t\t\"Error sending logs:\",\n\t\t\terror instanceof Error ? error.message : String(error),\n\t\t);\n\t\t// Re-add failed logs to the front of the queue\n\t\tlogQueue.unshift(...logsToSend);\n\t}\n};\n\n// Set up periodic flush\nsetInterval(flushLogs, FLUSH_INTERVAL);\n\nself.addEventListener(\n\t\"message\",\n\t(event: MessageEvent<{ logData: LogData }>) => {\n\t\tconst { logData } = event.data;\n\t\tlogQueue.push(logData);\n\n\t\t// Flush immediately if we've reached batch size\n\t\tif (logQueue.length >= MAX_BATCH_SIZE) {\n\t\t\tvoid flushLogs();\n\t\t}\n\t},\n);\n"]}